{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427e4f52",
   "metadata": {},
   "source": [
    "# WEEK 2: Data Scraping Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab144200",
   "metadata": {},
   "source": [
    "## What is Data Scraping Automation\n",
    "Data scraping automation is the process of using software to extract information from websites by replicating human-like actions such as clicking, scrolling, typing, and navigating pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77302adb",
   "metadata": {},
   "source": [
    "## Core Behaviour\n",
    "- Click\n",
    "- Scroll\n",
    "- Input\n",
    "- Hover\n",
    "- Delay\n",
    "- Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a390e4",
   "metadata": {},
   "source": [
    "## Google Maps Data Scraping A\n",
    "https://www.google.com/maps\n",
    "\n",
    "Task: Retrieve data for places that serve ramen in Malang City.\n",
    "\n",
    "Output: Title, address, and URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = \"https://www.google.com/maps/search/ramen+dekat+malang/\"\n",
    "driver.get(url)\n",
    "\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"article\"]'))\n",
    ")\n",
    "\n",
    "time.sleep(3.2)  \n",
    "\n",
    "result = []\n",
    "no_new_counter = 0\n",
    "seen_links = set()\n",
    "\n",
    "while len (result) < 20 and no_new_counter < 4:\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, 'div[role=\"article\"]')\n",
    "    new_found = 0\n",
    "\n",
    "    for item in items:\n",
    "        title_el = item.find_element(By.CSS_SELECTOR, 'div.qBF1Pd')\n",
    "        nama = title_el.text\n",
    "\n",
    "        link_el = item.find_element(By.CSS_SELECTOR, 'a.hfpxzc')\n",
    "        link = link_el.get_attribute('href')\n",
    "        \n",
    "        if link in seen_links:\n",
    "            continue\n",
    "        seen_links.add(link)\n",
    "\n",
    "        alamat = \"Tidak Ditemukan\"\n",
    "        els = item.find_elements(By.CSS_SELECTOR, 'span:last-child')\n",
    "\n",
    "        for el in els:\n",
    "            txt = el.text.strip()\n",
    "            if txt and any (kata in txt.lower() for kata in ['jl.', 'jln.' , 'jalan', 'no.', 'rt', 'rw', 'kota', 'kabupaten', 'provinsi']):\n",
    "                alamat = txt\n",
    "                break\n",
    "\n",
    "        result.append({'nama': nama, 'alamat': alamat, 'link': link})\n",
    "        new_found += 1\n",
    "\n",
    "    if len(result) >= 20:\n",
    "        break\n",
    "\n",
    "    container = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"feed\"]'))\n",
    "    )\n",
    "    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', container)\n",
    "    time.sleep(1.4)\n",
    "\n",
    "    ActionChains(driver).send_keys(Keys.END).perform()\n",
    "    time.sleep(0.6)\n",
    "    if new_found == 0:\n",
    "        no_new_counter += 1\n",
    "    else:\n",
    "        no_new_counter = 0\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "with open('ramen_malang.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['nama', 'alamat', 'link'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73578e",
   "metadata": {},
   "source": [
    "## Google Maps Data Scraping B\n",
    "https://www.google.com/maps\n",
    "\n",
    "Task: Retrieve data for places that serve nasi ayam within 1 km of Alun-Alun Kota Malang.\n",
    "\n",
    "Output: Title, address, coordinate, and URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8c901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import math\n",
    "\n",
    "center_lat = -7.9826145\n",
    "center_lng = 112.6308113\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  \n",
    "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = math.sin(dlat / 2) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2) ** 2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def extract_coordinates(url):\n",
    "    match = re.search(r\"!3d([-+]?\\d*\\.\\d+)!4d([-+]?\\d*\\.\\d+)\", url)\n",
    "    if match:\n",
    "        lat = float(match.group(1))\n",
    "        lng = float(match.group(2))\n",
    "        return lat, lng\n",
    "    return None, None\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--start-maximized')\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "url = f\"https://www.google.com/maps/search/nasi+ayam+di+dekat+alun+alun+malang/@{center_lat},{center_lng},17z/data=!3m1!4b1?entry=ttu&g_ep=EgoyMDI1MTIwMS4wIKXMDSoASAFQAw%3D%3D\"\n",
    "driver.get(url)\n",
    "\n",
    "WebDriverWait(driver, 20).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"article\"]'))\n",
    ")\n",
    "time.sleep(3.2)\n",
    "\n",
    "result = []\n",
    "final_result = []\n",
    "\n",
    "no_new_counter = 0 \n",
    "seen_links = set()\n",
    "while len(result) < 20 and no_new_counter < 4:\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, 'div[role=\"article\"]')\n",
    "    new_found = 0\n",
    "\n",
    "    for item in items:\n",
    "        title_el = item.find_element(By.CSS_SELECTOR, 'div.qBF1Pd')\n",
    "        nama = title_el.text\n",
    "\n",
    "        link_el = item.find_element(By.CSS_SELECTOR, 'a.hfpxzc')\n",
    "        link = link_el.get_attribute('href')\n",
    "\n",
    "        if link in seen_links:\n",
    "            continue\n",
    "        seen_links.add(link)\n",
    "\n",
    "        alamat = \"Tidak Ditemukan\"\n",
    "        els = item.find_elements(By.CSS_SELECTOR, 'span:last-child')\n",
    "\n",
    "        for el in els:\n",
    "            txt = el.text.strip()\n",
    "            if txt and any(kata in txt.lower() for kata in ['jl.', 'jln.' , 'jalan', 'no.', 'rt', 'rw', 'kota', 'kabupaten', 'provinsi']):\n",
    "                alamat = txt\n",
    "                break\n",
    "\n",
    "        result.append({'nama': nama, 'alamat': alamat, 'link': link})\n",
    "        new_found += 1\n",
    "\n",
    "    if len(result) >= 20:\n",
    "        break\n",
    "\n",
    "    container = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"feed\"]'))\n",
    "    )\n",
    "    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', container)\n",
    "    time.sleep(1.4)\n",
    "\n",
    "    ActionChains(driver).send_keys(Keys.END).perform()\n",
    "    time.sleep(0.6)\n",
    "    if new_found == 0:\n",
    "        no_new_counter += 1\n",
    "    else:\n",
    "        no_new_counter = 0\n",
    "\n",
    "    \n",
    "    for tempat in result:\n",
    "        lat, lng = extract_coordinates(tempat['link'])\n",
    "        if lat is None or lng is None:\n",
    "            continue\n",
    "        jarak = haversine(center_lat, center_lng, lat, lng)\n",
    "        if jarak <= 1.0:\n",
    "            final_result.append({\n",
    "                'nama': tempat['nama'],\n",
    "                'alamat': tempat['alamat'],\n",
    "                'link': tempat['link'],\n",
    "                'jarak_km': round(jarak, 2)\n",
    "            })\n",
    "driver.quit()\n",
    "\n",
    "with open('nasi_ayam_malang_dekat_alun_alun.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['nama', 'alamat', 'link', 'jarak_km'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6804c67",
   "metadata": {},
   "source": [
    "## Google Maps Data Scraping C (Challenge)\n",
    "https://www.google.com/maps\n",
    "\n",
    "Task: Retrieve all reviews from the Malang Strudel branch that is closest to Malang Town Square.\n",
    "\n",
    "Output: Username, photos included in the review, user’s, posting time, star rating, and review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef2bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Cabang Malang Strudel terdekat ditemukan!\n",
      "Jarak dari center point: 1.9 km\n",
      "Link: https://www.google.com/maps/place/Malang+Strudel/data=!4m7!3m6!1s0x2dd6282680e35b09:0x8287e446862baa43!8m2!3d-7.9734574!4d112.623579!16s%2Fg%2F11c5zsdwcl!19sChIJCVvjgCYo1i0RQ6orhkbkh4I?authuser=0&hl=id&rclk=1\n",
      "============================================================\n",
      "\n",
      "Memuat ulasan...\n",
      "Membuka ulasan lengkap...\n",
      "\n",
      "Memproses 10 review...\n",
      "\n",
      "Review 1 (Yusuf Noufal Rahman): Ditemukan 2 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_1_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_1_foto_2.jpg\n",
      "Review 2 (Ilman Alqarni): Ditemukan 2 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_2_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_2_foto_2.jpg\n",
      "Review 3 (Ratih SWP): Ditemukan 4 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_3_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_3_foto_2.jpg\n",
      "  ✓ Foto 3 disimpan: foto_ulasan_strudel\\review_3_foto_3.jpg\n",
      "  ✓ Foto 4 disimpan: foto_ulasan_strudel\\review_3_foto_4.jpg\n",
      "Review 4 (Chia Lara): Ditemukan 1 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_4_foto_1.jpg\n",
      "Review 5 (Dani Pratiwi): Ditemukan 4 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_5_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_5_foto_2.jpg\n",
      "  ✓ Foto 3 disimpan: foto_ulasan_strudel\\review_5_foto_3.jpg\n",
      "  ✓ Foto 4 disimpan: foto_ulasan_strudel\\review_5_foto_4.jpg\n",
      "Review 6 (Erri Herdianto): Ditemukan 2 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_6_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_6_foto_2.jpg\n",
      "Review 7 (Regina Rahardjo): Ditemukan 2 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_7_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_7_foto_2.jpg\n",
      "Review 8 (Djer Herdiman2): Ditemukan 4 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_8_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_8_foto_2.jpg\n",
      "  ✓ Foto 3 disimpan: foto_ulasan_strudel\\review_8_foto_3.jpg\n",
      "  ✓ Foto 4 disimpan: foto_ulasan_strudel\\review_8_foto_4.jpg\n",
      "Review 9 (gadis 785): Ditemukan 2 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_9_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_9_foto_2.jpg\n",
      "Review 10 (Irvan Adriansyah): Ditemukan 3 foto\n",
      "  ✓ Foto 1 disimpan: foto_ulasan_strudel\\review_10_foto_1.jpg\n",
      "  ✓ Foto 2 disimpan: foto_ulasan_strudel\\review_10_foto_2.jpg\n",
      "  ✓ Foto 3 disimpan: foto_ulasan_strudel\\review_10_foto_3.jpg\n",
      "\n",
      "============================================================\n",
      "✓ SELESAI!\n",
      "============================================================\n",
      "✓ CSV disimpan: ulasan_strudel_malang_town_square.csv\n",
      "✓ Total review: 10\n",
      "✓ Folder foto: foto_ulasan_strudel\n",
      "✓ Cabang terdekat: 1.9 km dari center\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "import math\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "CENTER_LAT = -7.957211\n",
    "CENTER_LNG = 112.618347\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_argument(\"disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, 20)\n",
    "driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\n",
    "    \"source\": \"\"\"\n",
    "        Object.defineProperty(navigator, 'webdriver', {get: () => false});\n",
    "        window.navigator.chrome = { runtime: {} };\n",
    "        Object.defineProperty(navigator, 'languages', {get: () => ['id-ID', 'id']});\n",
    "        Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});\n",
    "      \"\"\"\n",
    "})\n",
    "\n",
    "driver.get(\"https://www.google.com/maps/search/malang+strudel+dekat+malang+town+square/\")\n",
    "time.sleep(6)\n",
    "wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"article\"]'))\n",
    ")\n",
    "\n",
    "results = []\n",
    "seen_links = set()\n",
    "scroll_attempts_without_new = 0\n",
    "max_attempts_without_new = 4\n",
    "\n",
    "while scroll_attempts_without_new < max_attempts_without_new:\n",
    "    items = driver.find_elements(By.CSS_SELECTOR, 'div[role=\"article\"]')\n",
    "    new_found = 0\n",
    "\n",
    "    for item in items:\n",
    "        link_el = item.find_element(By.CSS_SELECTOR, 'a.hfpxzc')\n",
    "        link = link_el.get_attribute('href')\n",
    "\n",
    "        if link in seen_links:\n",
    "            continue\n",
    "        seen_links.add(link)\n",
    "\n",
    "        results.append({'link': link})\n",
    "        new_found += 1\n",
    "\n",
    "    if new_found == 0:\n",
    "        scroll_attempts_without_new += 1\n",
    "    else:\n",
    "        scroll_attempts_without_new = 0\n",
    "\n",
    "    container = wait.until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, 'div[role=\"feed\"]'))\n",
    "    )\n",
    "    driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', container)\n",
    "    time.sleep(2)\n",
    "\n",
    "candidates = []\n",
    "R = 6371\n",
    "\n",
    "IMAGE_FOLDER = 'foto_ulasan_strudel'\n",
    "if not os.path.exists(IMAGE_FOLDER):\n",
    "    os.makedirs(IMAGE_FOLDER)\n",
    "\n",
    "for r in results:\n",
    "    match = re.search(r\"!3d([-+]?\\d*\\.\\d+)!4d([-+]?\\d*\\.\\d+)\", r['link'])\n",
    "    if match:\n",
    "        lat = float(match.group(1))\n",
    "        lng = float(match.group(2))\n",
    "\n",
    "        lat1, lon1, lat2, lon2 = map(math.radians, [CENTER_LAT, CENTER_LNG, lat, lng])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "        distance = R * c\n",
    "\n",
    "        candidates.append({**r, 'jarak_km': round(distance, 2)})\n",
    "\n",
    "    if not candidates:\n",
    "        driver.quit()\n",
    "\n",
    "    closest = min(candidates, key=lambda x: x['jarak_km'])\n",
    "    driver.get(closest['link'])\n",
    "    time.sleep(2.1)\n",
    "\n",
    "    review_tab = wait.until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//button[.//div[contains(text(), \"Ulasan\")]]')))\n",
    "    driver.execute_script(\"arguments[0].click();\", review_tab)\n",
    "    time.sleep(2)\n",
    "\n",
    "    panel = driver.find_element(By.XPATH, '//div[contains(@class, \"m6QErb\") and contains(@class, \"DxyBCb\") and contains(@class, \"kA9KIf\") and contains(@class, \"dS8AEf\")]')\n",
    "\n",
    "    for _ in range(10):\n",
    "        driver.execute_script('arguments[0].scrollBy(0,1400)', panel)\n",
    "        time.sleep(1)\n",
    "\n",
    "    for _ in range(10):\n",
    "        buttons = panel.find_elements(By.XPATH, './/button[.//span[contains(text(), \"lainya\")]]')\n",
    "        for btn in buttons:\n",
    "            try:\n",
    "                driver.execute_script(\"arguments[0].click();\", btn)\n",
    "                time.sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "        time.sleep(2)\n",
    "    \n",
    "    reviews = driver.find_elements(By.XPATH, './/div[contains(@class, \"jftiEf\") and contains(@class, \"fontBodyMedium\")]')[:10]\n",
    "    hasil_ulasan = []\n",
    "    for i, review in enumerate(reviews, start=1):\n",
    "        nama = review.find_element(By.XPATH, './/div[contains(@class, \"d4r55\")]').text.strip()\n",
    "        \n",
    "        rating_el = review.find_element(By.XPATH, './/span[contains(@class, \"kvMYJc\")]//span')\n",
    "        stars = rating_el.find_elements(By.XPATH, './/span[contains(@aria-label, \"bintang\")]')\n",
    "        bintang_count = len(stars)\n",
    "        \n",
    "        ulasan_text = review.find_element(By.XPATH, './/span[contains(@class, \"wiI7pd\")]').text.strip()\n",
    "        tanggal = review.find_element(By.XPATH, './/span[contains(@class, \"rsqaWe\")]').text.strip()\n",
    "        \n",
    "        foto_paths = []\n",
    "        photo_buttons = review.find_elements(By.CSS_SELECTOR, 'div.KtCyie button.Tya61d')\n",
    "        \n",
    "        for idx, btn in enumerate(photo_buttons):\n",
    "            style = btn.get_attribute('style')\n",
    "            url_match = re.search(r'url\\(\"?(.+?)\"?\\)', style)\n",
    "            \n",
    "            img_url = url_match.group(1)\n",
    "            img_name = f\"review_{i}_foto_{idx+1}.jpg\"\n",
    "            img_path = os.path.join(IMAGE_FOLDER, img_name)\n",
    "            \n",
    "            img_response = requests.get(img_url, timeout=10)\n",
    "            with open(img_path, 'wb') as f:\n",
    "                f.write(img_response.content)\n",
    "            foto_paths.append(img_path)\n",
    "        \n",
    "        hasil_ulasan.append({\n",
    "            'nomor': i,\n",
    "            'nama': nama,\n",
    "            'bintang': bintang_count,\n",
    "            'ulasan': ulasan_text,\n",
    "            'tanggal': tanggal,\n",
    "            'foto_path': \"; \".join(foto_paths) if foto_paths else \"Tidak ada foto\"\n",
    "        })\n",
    "\n",
    "csv_filename = 'ulasan_strudel_malang_town_square.csv'\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['nomor', 'nama', 'bintang', 'ulasan', 'tanggal', 'foto_path'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(hasil_ulasan)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf836fd5",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
